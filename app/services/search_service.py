from typing import List, Dict, Any
from app.core.database import vector_db
from app.services.embedding_service import embedding_service


class SearchService:
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.vector_db = vector_db
        self.embedding_service = embedding_service
    
    def search_documents(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            query_embedding = self.embedding_service.get_single_embedding(query)
            
            if not query_embedding:
                raise ValueError("ì§ˆë¬¸ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.vector_db.search(
                query_embedding=query_embedding,
                n_results=max_results
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            if search_results and 'documents' in search_results:
                documents = search_results['documents'][0]
                metadatas = search_results.get('metadatas', [[]])[0]
                distances = search_results.get('distances', [[]])[0]
                
                for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):
                    formatted_results.append({
                        "content": doc,
                        "metadata": metadata or {},
                        "distance": distance,
                        "relevance_score": 1 - distance  # ê±°ë¦¬ë¥¼ ê´€ë ¨ì„± ì ìˆ˜ë¡œ ë³€í™˜
                    })
            
            print(f"ğŸ” '{query}'ì— ëŒ€í•œ {len(formatted_results)}ê°œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
            return formatted_results
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise
    
    def get_most_relevant_chunks(self, query: str, max_results: int = 3) -> List[str]:
        """ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ì²­í¬ë“¤ ë°˜í™˜"""
        try:
            search_results = self.search_documents(query, max_results)
            
            # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
            sorted_results = sorted(
                search_results, 
                key=lambda x: x['relevance_score'], 
                reverse=True
            )
            
            # ì„ê³„ê°’ ì´ìƒì˜ ê´€ë ¨ì„±ë§Œ í•„í„°ë§
            relevant_chunks = [
                result['content'] for result in sorted_results
                if result['relevance_score'] > 0.7  # 70% ì´ìƒ ê´€ë ¨ì„±
            ]
            
            return relevant_chunks
            
        except Exception as e:
            print(f"âŒ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ ì •ë³´"""
        try:
            db_info = self.vector_db.get_collection_info()
            return {
                "database_info": db_info,
                "embedding_model": "OpenAI text-embedding-ada-002 (í´ë°±: sentence-transformers)",
                "search_algorithm": "Cosine Similarity"
            }
        except Exception as e:
            return {"error": f"í†µê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}"}


# ì „ì—­ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
search_service = SearchService() 